# 情感分类

## 定义
 &#8195;情感分析或意见挖掘是人们的观点，情绪，评估对诸如产品，服务，组织等实体的态度。该领域的发展和快速起步得益于网络上的社交媒体，例如产品评论，论坛讨论，微博，微信的快速发展，因为这是人类历史上第一次有如此巨大数字量的形式记录。自2000年初以来，情绪分析已经成长为自然语言处理（NLP）中最活跃的研究领域之一。也是在数据挖掘，Web挖掘，文本挖掘和信息检索方面有广泛的研究。事实上，它已经从计算机科学蔓延到管理科学和社会科学，如市场营销，金融，政治学，通讯，医疗科学，甚至是历史，由于其重要的商业性引发整个社会的共同关注。这种扩散是由于意见是事实的中心，几乎所有的人类活动，在相当程度上，很在意别人怎么看。出于这个原因，无论何时我们需要做出决定，我们都会经常寻找别人的意见。这不仅是对企业而言对个人也是如此。

## 方法
 &#8195;现有的文本情感分析的途径大致可以集合成四类：关键词识别、词汇关联、统计方法和概念级技术。关键词识别是利用文本中出现的清楚定义的影响词（affect words），例如“开心”、“难过”、“伤心”、“害怕”、“无聊”等等，来影响分类。词汇关联除了侦查影响词以外，还附于词汇一个和某项情绪的“关联”值。统计方法通过调控机器学习中的元素，比如潜在语意分析（latent semantic analysis），SVM（support vector machines），TFIDF等。

### TF-IDF
 - 主要思想是：如果某个词或短语在一篇文章中出现的频率TF高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。这里介绍一种对 TF-IDF 的傻瓜理解法：TF：词频，表示特征t在文档D中出现的次数，比如一篇谈论乔布斯的文章，可预期“iphone”、“苹果”的TF值为较高。DF：包含特征t的文档数，DF越高，表示特征X对于衡量文档之间的区别作用低。比如“我”、“的”这样的词，DF一般最高。IDF：定义为IDF =log(|D|/DF)，|D|为所有文档数。与DF成反比，IDF值越高，表示特征t对区别文档的意义越大。最终定义：TF-IDF=TF*IDF

### 贝叶斯公式
 - 贝叶斯公式：P(C|X)=P(X|C)P(C)/P(X)先验概率P(C)通过计算训练集中属于每一个类的训练样本所占的比例，类条件概率P(X|C)的估计—朴素贝叶斯，假设事物属性之间相互条件独立，P(X|C)=∏P(xi|ci)。朴素贝叶斯有两用常用的模型，概率定义略有不同，如下：设某文档d=(t1,t2,…,tk)，tk是该文档中出现过的单词，允许重复。多项式模型先验概率P(c)= 类c下单词总数/整个训练样本的单词总数。条件概率P(tk|c)=(类c下单词tk在各个文档中出现过的次数之和+1)/( 类c下单词总数+|V|)伯努利模型：先验概率P(c)= 类c下文件总数/整个训练样本的文件总数。条件概率P(tk|c)=(类c下包含单词tk的文件数+1)/(类c下单词总数+2)通俗点解释两种模型不同点在于：计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反例”参与的。
